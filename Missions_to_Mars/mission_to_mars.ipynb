{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import pymongo\n",
    "from splinter import Browser\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splinter\n",
    "executable_path = {'executable_path': 'chromedriver'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NASA Mars News\n",
    "# * Scrape the [Mars News Site](https://redplanetscience.com/) and collect the latest News Title and Paragraph Text. Assign the text to variables that you can reference later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# visit Mars News Site\n",
    "url = \"https://redplanetscience.com/\"\n",
    "browser.visit(url)\n",
    "# html created\n",
    "html = browser.html\n",
    "# beautifulsoup object created\n",
    "soup = bs(html, \"html.parser\")\n",
    "# beautifulsoup find latest news data\n",
    "data = soup.find(\"div\", id=\"news\")\n",
    "# use bs to get news title and paragraph info\n",
    "news_title = data.find(\"div\", class_=\"content_title\").text\n",
    "news_content = data.find(\"div\", class_=\"article_teaser_body\").text\n",
    "print(\"News Title: \" + news_title)\n",
    "print(\"----------\")\n",
    "print(\"Summary: \" + news_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### JPL Mars Space Images - Featured Image\n",
    "# * Visit the url for the Featured Space Image site [here](https://spaceimages-mars.com).\n",
    "# * Use splinter to navigate the site and find the image url for the current Featured Mars Image and assign the url string to a variable called `featured_image_url`.\n",
    "# * Make sure to find the image url to the full size `.jpg` image.\n",
    "# * Make sure to save a complete url string for this image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visit JPL Mars Space Images\n",
    "img_url = 'https://spaceimages-mars.com/'\n",
    "browser.visit(img_url)\n",
    "# create soup object to parse html\n",
    "html_img = browser.html\n",
    "images_soup = bs(html_img, \"html.parser\")\n",
    "rel_image = images_soup.find(\"img\", class_=\"headerimage fade-in\")[\"src\"]\n",
    "featured_image_url = img_url + rel_image\n",
    "\n",
    "print(featured_image_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Mars Facts\n",
    "# * Visit the Mars Facts webpage [here](https://galaxyfacts-mars.com) and use Pandas to scrape the table containing facts about the planet including Diameter, Mass, etc.\n",
    "# * Use Pandas to convert the data to a HTML table string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visit Mars Facts webpage\n",
    "facts_url = \"https://galaxyfacts-mars.com/\"\n",
    "browser.visit(url)\n",
    "# Use panda's `read_html` to parse the url\n",
    "facts_table = pd.read_html(facts_url)\n",
    "\n",
    "print(facts_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert table to pandas dataframe\n",
    "facts_df = facts_table[1]\n",
    "facts_df.columns=['Description','Value']\n",
    "print(facts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to html\n",
    "facts_html = facts_df.to_html()\n",
    "print(facts_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Mars Hemispheres\n",
    "# * Visit the astrogeology site [here](https://marshemispheres.com/) to obtain high resolution images for each of Mar's hemispheres.\n",
    "# * You will need to click each of the links to the hemispheres in order to find the image url to the full resolution image.\n",
    "# * Save both the image url string for the full resolution hemisphere image, and the Hemisphere title containing the hemisphere name. Use a Python dictionary to store the data using the keys `img_url` and `title`.\n",
    "#. * Append the dictionary with the image url string and the hemisphere title to a list. This list will contain one dictionary for each hemisphere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visit the astrogeology site\n",
    "hemis_url = \"https://marshemispheres.com/\"\n",
    "browser.visit(hemis_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# beautiful soup\n",
    "html_hemis = browser.html\n",
    "hemis_soup = bs(html_hemis, \"html.parser\")\n",
    "hemis_info = hemis_soup.find_all('div', class_='item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hemis_list = []\n",
    "for item in hemis_info:\n",
    "    title = item.find('h3').text\n",
    "    browser.find_by_text(title).first.click()\n",
    "    html = browser.html\n",
    "    soup = bs(html, 'html.parser')\n",
    "    url_ext = soup.find('div', class_='downloads').ul.li.a['href']\n",
    "    img_url = hemis_url + url_ext\n",
    "    hemis_dict = {'Title:':title,'IMG URL':img_url}\n",
    "    hemis_list.append(hemis_dict)\n",
    "\n",
    "hemis_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}